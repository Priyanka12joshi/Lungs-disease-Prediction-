# -*- coding: utf-8 -*-
"""Lungs_cancer_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D01c7PWL47tDZXjeuAfTjXM2fQJhESqu

# **Import Libraies**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder

"""#**Load and read the dataset**"""

df = pd.read_csv("/content/survey lung cancer.csv")
df.head()

"""#**Check the shape of the dataset**"""

df.shape

df.describe()

df.info()

"""#**Check Null/Missing values**"""

df.isnull().sum()

"""#**Check the data types of variables and duplicate value**"""

df.dtypes

df.duplicated().sum()

df = df.drop_duplicates()
df.duplicated().sum()

"""#**Create Data Visualisations**

**Question  1: What is the distribution of age across different genders?**
"""

plt.figure(figsize=(10,5))
ax = sns.histplot(data=df, x='AGE', kde=True, hue='GENDER', palette="muted", multiple="stack", bins=15)

for p in ax.patches:
    ax.annotate(f'{int(p.get_height())}',
                (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center',
                fontsize=10, color='black',
                xytext=(0, 5), textcoords='offset points')

plt.title("Distribution of Age Across Different Genders")
plt.xlabel("Age", fontsize=12)
plt.ylabel("Count", fontsize=12)
plt.legend(title="Gender", labels=['Male', 'Female'])
plt.show()

""" **Question 2: What is the correlation between features and lung cancer?**"""

le = LabelEncoder()
df['GENDER'] = le.fit_transform(df['GENDER'])
df['LUNG_CANCER'] = le.fit_transform(df['LUNG_CANCER'])
correlation = df.corr(method='pearson')
print(correlation.columns)

plt.figure(figsize=(12, 10))
sns.heatmap(correlation[['LUNG_CANCER']].sort_values(by='LUNG_CANCER', ascending=False), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Pearson Correlation of Features with Lung Cancer', fontsize=14)
plt.show()

"""**Question 3: How does smoking affect the likelihood of having lung cancer?**"""

plt.figure(figsize=(8,6))
ax = sns.countplot(x='SMOKING',hue='LUNG_CANCER', data=df, palette= 'Set2')
for p in ax.patches:
  ax.annotate(f'{int(p.get_height())}',
              (p.get_x()+p.get_width()/2, p.get_height()),
              ha = 'center', va='center',
              fontsize= 10,color='black',
              xytext=(0,5), textcoords='offset points')
plt.title("Smoking Status and Lung Cancer")
plt.xlabel("Smoking Status")
plt.ylabel("Count")
plt.legend(title="Lung Cancer",  labels= ['No','Yes'])
plt.show()

"""**Question 4: Is there a relationship between fatigue and lung cancer?**"""

plt.figure(figsize=(8,6))
ax = sns.boxplot(x='LUNG_CANCER', y= 'FATIGUE ', data=df, palette= 'coolwarm')
for i in range(2):
  median_value = df[df['LUNG_CANCER']==i]['FATIGUE '].median()
  ax.annotate(
      f'median: {median_value:.2f}',
      xy =(i,median_value),
      xytext=(0,5), textcoords='offset points',
      ha = 'center', va= 'center',
      fontsize= 10, color= 'black')


plt.title("Relationship between Fatigue and Lung Cancer")
plt.xlabel("Lung Cancer")
plt.ylabel("Fatigue")
plt.show()

"""**Question 5: What is the distribution of individuals with and without lung cancer in the dataset?**"""

lung_cancer_counts = df['LUNG_CANCER'].value_counts()
def func(pct, allvals):
  absolute= int(pct/100.*sum(allvals))
  return f"{absolute} ({pct:.1f}%)"
plt.figure(figsize=(8,6))
plt.pie(lung_cancer_counts,labels=['No Cancer','Yes Lung cancer'],autopct=lambda pct: func(pct,lung_cancer_counts), startangle=90, colors=['#66b3ff','#ff9999'])
plt.title('Distribution of Individual with or without Lung Cancer')
plt.show()

"""#**Build Models (for build models, we have to split the dataset into train and test and also set a target variable)**"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['LUNG_CANCER'] = le.fit_transform(df['LUNG_CANCER'])

x = df.drop(columns=['LUNG_CANCER'])
y = df['LUNG_CANCER']

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y, test_size =0.2, random_state =42)



"""**Data preprocesing**"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
y_train = sc.transform(x_test)

"""**Classification report of  Random Forest Model**"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score,classification_report, confusion_matrix
rf = RandomForestClassifier(n_estimators = 100, random_state=42)
rf.fit(x_train,y_train)
y_pred = rf.predict(x_test)
print(accuracy_score(y_test,y_pred))
print(classification_report(y_test,y_pred))

"""**Classification report of Decision Tree Model**



"""

from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(random_state = 42)
dt.fit(x_train, y_train)
y_pred= dt.predict(x_test)
print(accuracy_score(y_test,y_pred))
print(classification_report(y_test,y_pred))

"""**Classification report of Support Vector Machine**"""

from sklearn.svm import SVC

svm = SVC(kernel='linear', random_state=42)
svm.fit(x_train,y_train)
y_pred = svm.predict(x_test)
print(accuracy_score(y_test,y_pred))
print(classification_report(y_test,y_pred))

models = ['SVM', 'Decision Tree', 'Random Forest']
accuracies = [0.9285714285714286, 0.9107142857142857, 0.8571428571428571]
best_model = models[accuracies.index(max(accuracies))]
plt.figure(figsize=(8, 6))
bars = plt.bar(models, accuracies, color=['#66b3ff', '#99ff99', '#ff9999'])
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f'{yval*100:.1f}%', ha='center', va='bottom', fontsize=8)
plt.title('Comparison of Classification Models Based on Accuracy', fontsize=14)
plt.xlabel('Model', fontsize=12)
plt.ylabel('Accuracy', fontsize=12)
plt.show()
print(f"The best classification model based on accuracy is: {best_model}")



"""**Regression Model**

:**Evaluation Score of Linear Regression Model**
"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error,r2_score, mean_absolute_error

lr = LinearRegression()
lr.fit(x_train,y_train)
y_pred = lr.predict(x_test)

print(f"Mean squared ,error:"{mean_squared_error(y_test,y_pred)})
print(f"Mean absolute error:",{mean_absolute_error(y_test,y_pred)})
print(f"R2 score:",{r2_score(y_test,y_pred)})

"""**Evaluation Score of Logistic Regression**"""

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(x_train,y_train)
y_pred = lr.predict(x_test)

print(f"Mean squared ,error:",{mean_squared_error(y_test,y_pred)})
print(f"Mean absolute error:",{mean_absolute_error(y_test,y_pred)})
print(f"R2 score:",{r2_score(y_test,y_pred)})

"""**Evaluation Score of Random Forest Regressor Model**"""

from sklearn.ensemble import RandomForestRegressor
rf1 = RandomForestRegressor()
rf1.fit(x_train,y_train)
y_pred= rf1.predict(x_test)
print(f"Mean Square error:",{mean_squared_error(y_test,y_pred)})
print(f"Mean Absolute error:",{mean_absolute_error(y_test,y_pred)})
print(f"R2 score:",{r2_score(y_test,y_pred)})

models = ['Linear Regression','Logistic Regression','Random Forest Regressor']
accuracies=[0.442851068533897,0.4696969696969696,0.5242651515151514]
best_model = models[accuracies.index(max(accuracies))]
plt.figure(figsize=(8, 6))
bars = plt.bar(models, accuracies, color=['#66b3ff', '#99ff99', '#ff9999'])
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f'{yval*100:.1f}%', ha='center', va='bottom', fontsize=8)
plt.title('Comparison of Regression Models Based on Accuracy', fontsize=14)
plt.xlabel('Model', fontsize=12)
plt.ylabel('Accuracy', fontsize=12)
plt.show()
print(f"The best Regression model based on accuracy is: {best_model}")

"""#**Clustering Model**

**Evaluation Score of KMean Clustering**
"""

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
x= df.drop(columns=['LUNG_CANCER'])
scaler = StandardScaler()
x_scaled = scaler.fit_transform(x)
kmeans = KMeans(n_clusters=3, random_state =42)
kmeans.fit(x_scaled)
sil_score_kmeans = silhouette_score(x_scaled, kmeans.labels_)
print(f"Silhouette Score (K-Means): {sil_score_kmeans}")

"""**Evaluation Score of Agglomerative Clustering**"""

from sklearn.cluster import AgglomerativeClustering
Ag = AgglomerativeClustering(n_clusters = 3)
Ag.fit_predict(x_scaled)
sil_score_Ag = silhouette_score(x_scaled,Ag.labels_)
print(f"Silhoutte Score (Agglomerative Clustering): {sil_score_Ag}")

"""**Evaluation Score of Gaussian Mixture**"""

from sklearn.mixture import GaussianMixture
gmm = GaussianMixture(n_components = 2, random_state=42)
gmm_labels = gmm.fit_predict(x_scaled)
sil_score_gmm = silhouette_score(x_scaled, gmm_labels)
print(f"Silhoutte Score (Gaussian Mixture): {sil_score_gmm}")

models = ['KMeans','Agglomerative Clustering','Gaussian Mixture']
accuracies = [0.12914927043712, 0.10987143890628158, 0.12082204384990063]
plt.figure(figsize=(8,6))
best_model = models[accuracies.index(max(accuracies))]
bars = plt.bar(models, accuracies, color = ['#ffb3e6', '#ff9999', '#66b3ff'])
for bar in bars:
  yval = bar.get_height()
  plt.text(bar.get_x() + bar.get_width()/2, yval + 0.001, f'{yval:f}', ha= 'center', va='bottom', fontsize = 8)
plt.title('Comparison of Clustering Models based on Silhouette Score', fontsize=12)
plt.xlabel('Model', fontsize =12)
plt.ylabel('Silhouette Score', fontsize = 12)
plt.show()
print(f"The best classification model based on accuracy is: {best_model}")







